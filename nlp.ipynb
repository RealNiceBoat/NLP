{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom xgboost import XGBClassifier\nimport pickle\nfrom sklearn.multiclass import OneVsRestClassifier\ntrain = pd.read_csv('../input/til2020/TIL_NLP_train_dataset.csv', index_col='id')\ntest = pd.read_csv('../input/til2020/TIL_NLP_test_dataset.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxgtrain, xgtest = train_test_split(train, test_size=0.1, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training fastai model - creating & finetuning a language model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.text import *\n\n# Create databunch\ndata = (TextList.from_df(train, cols='word_representation')\n                .split_by_rand_pct(0.2)\n                .label_for_lm()  \n                .databunch(bs=48))\ndata.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data,AWD_LSTM, drop_mult=0.3)\n\n# select the appropriate learning rate\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)\nmin_grad_lr = learn.recorder.min_grad_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, min_grad_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(2, 1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('enc_final')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training fastai model - creating classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols = [\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"]\n\ntest_datalist = TextList.from_df(test, cols='word_representation', vocab=data.vocab)\n\ndata_clas = (TextList.from_df(train, cols='word_representation', vocab=data.vocab)\n             .split_by_rand_pct(0.2)\n             .label_from_df(cols= label_cols , classes=label_cols)\n             .add_test(test_datalist)\n             .databunch(bs=32))\n\ndata_clas.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n\n# load the encoder saved  \nlearn_classifier.load_encoder('enc_final')\nlearn_classifier.freeze()\n\n# select the appropriate learning rate\nlearn_classifier.lr_find()\n\n# we typically find the point where the slope is steepest\nlearn_classifier.recorder.plot(suggestion=True)\nmin_classifier_grad_lr = learn_classifier.recorder.min_grad_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.fit_one_cycle(5, min_classifier_grad_lr)\n\nlearn_classifier.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.freeze_to(-2)\nlearn_classifier.fit_one_cycle(4, slice(5e-3, 2e-3), moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.fit_one_cycle(10, slice(5e-3, 2e-3), moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.unfreeze()\nlearn_classifier.fit_one_cycle(10, slice(2e-3/100, 2e-3), moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.fit_one_cycle(1, slice(2e-3/100, 2e-3), moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.save('clas_final')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,y,losses = learn_classifier.get_preds(with_loss=True)\ninterp = ClassificationInterpretation(learn_classifier, preds, y, losses)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds, target = learn_classifier.get_preds(DatasetType.Test, ordered=True)\nlabels_prob = preds.numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = [[1 if x > 0.5 else 0 for idx,x in enumerate(i) ] for i in labels_prob]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating XGBoost model for blending with fastai model"},{"metadata":{"trusted":true},"cell_type":"code","source":"Ytrain = xgtrain[[\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"]].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf1 = TfidfVectorizer()\ntfidf1.fit(train['word_representation'])\nX_text = tfidf1.transform(xgtrain['word_representation']).toarray()\n\nXtrain1 = pd.DataFrame(X_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = OneVsRestClassifier(XGBClassifier(n_estimators=1000, random_state=0, tree_method='gpu_hist', gpu_id=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(Xtrain1, Ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = OneVsRestClassifier(XGBClassifier(n_estimators=500, random_state=0, tree_method='gpu_hist', gpu_id=0))\nmodel2.fit(Xtrain1, Ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ytest = xgtest[[\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"]].values\nX_testtext = tfidf1.transform(xgtest['word_representation']).toarray()\nXtest1 = pd.DataFrame(X_testtext)\n\ny_pred_prob = model1.predict_proba(Xtest1)\ny_pred_new = model1.predict(Xtest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob2 = model2.predict_proba(Xtest1)\ny_pred_new2 = model2.predict(Xtest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\n\ndef get_metrics(y_test, y_predicted):\n    # true positives / (true positives+false positives)\n    precision = precision_score(y_test, y_predicted, average='micro')             \n    # true positives / (true positives + false negatives)\n    recall = recall_score(y_test, y_predicted, average='micro')\n    # harmonic mean of precision and recall\n    f1 = 2 * (precision * recall) / (precision + recall)\n    # true positives + true negatives/ total\n    accuracy = accuracy_score(y_test, y_predicted)\n    return f1, precision, recall, accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_thresh(Ytest, prob):\n    thresholds = []\n    for thresh in np.arange(0.1, 0.501, 0.01):\n        thresh = np.round(thresh, 2)\n        y_pred_comb = [[1 if x > thresh else 0 for idx,x in enumerate(i) ] for i in prob]\n        res = get_metrics(Ytest, y_pred_comb)[0]\n        thresholds.append([thresh, res])\n        #print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n    thresholds.sort(key=lambda x: x[1], reverse=True)\n    best_thresh = thresholds[0][0]\n    print(\"Best threshold: \", best_thresh)\n    return best_thresh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh1 = calculate_thresh(Ytest, y_pred_prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh2 = calculate_thresh(Ytest, y_pred_prob2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred1 = [[1 if x > thresh1 else 0 for idx,x in enumerate(i) ] for i in y_pred_prob]\nresults1t = get_metrics(Ytest, y_pred1)\nprint(results1t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred2 = [[1 if x > thresh2 else 0 for idx,x in enumerate(i) ] for i in y_pred_prob2]\nresults2t = get_metrics(Ytest, y_pred2)\nprint(results2t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labels_prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_testtext1 = tfidf1.transform(test['word_representation']).toarray()\nXtest1 = pd.DataFrame(X_testtext1)\ntest_predprob = model2.predict_proba(Xtest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_predprob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comb = 0.25*(labels_prob*3 + test_predprob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(comb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = [[1 if x > 0.45 else 0 for idx,x in enumerate(i) ] for i in labels_prob]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/til2020/NLP_submission_example.csv')\nsubmission[[\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"]] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission19.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}