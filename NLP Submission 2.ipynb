{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom xgboost import XGBClassifier\nimport pickle\nfrom sklearn.multiclass import OneVsRestClassifier\ntrain = pd.read_csv('../input/til2020/TIL_NLP_train_dataset.csv', index_col='id')\nYtrain = train[[\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"]].values","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf1 = TfidfVectorizer()\ntfidf1.fit(train['word_representation'])\nX_text1 = tfidf1.transform(train['word_representation']).toarray()\n\n#pickle.dump(tfidf1, open(\"tfidf_uni.pickle\", \"wb\"))\n\nXtrain1 = pd.DataFrame(X_text1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf2 = TfidfVectorizer(ngram_range=(1, 2))\ntfidf2.fit(train['word_representation'])\nX_text2 = tfidf2.transform(train['word_representation']).toarray()\nXtrain2 = pd.DataFrame(X_text2)\n\n#pickle.dump(tfidf2, open(\"tfidf_bi.pickle\", \"wb\"))","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\n\ndef get_metrics(y_test, y_predicted):\n    # true positives / (true positives+false positives)\n    precision = precision_score(y_test, y_predicted, average='micro')             \n    # true positives / (true positives + false negatives)\n    recall = recall_score(y_test, y_predicted, average='micro')\n    # harmonic mean of precision and recall\n    f1 = 2 * (precision * recall) / (precision + recall)\n    # true positives + true negatives/ total\n    accuracy = accuracy_score(y_test, y_predicted)\n    return f1, precision, recall, accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = OneVsRestClassifier(XGBClassifier(n_estimators=100, random_state=0, tree_method='gpu_hist', gpu_id=0))\nmodel1.fit(Xtrain1, Ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(model1, open('tfidf_uni.sav', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"../input/xgboostnlp/tfidf_uni.sav\", 'rb') as model:\n    model1 = pickle.load(model)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"../input/xgboostnlp/tfidf_bi.sav\", 'rb') as model:\n    model2 = pickle.load(model)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/til2020/TIL_NLP_test_dataset.csv', index_col='id')\nX_testtext1 = tfidf1.transform(test['word_representation']).toarray()\nXtest1 = pd.DataFrame(X_testtext1)\ny_pred_prob1 = model1.predict_proba(Xtest1)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = OneVsRestClassifier(XGBClassifier(n_estimators=100, random_state=0, tree_method='gpu_hist', gpu_id=0))\nmodel2.fit(Xtrain2, Ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(model2, open('tfidf_bi.sav', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_testtext1 = tfidf1.transform(test['word_representation']).toarray()\nXtest1 = pd.DataFrame(X_testtext1)\ny_pred_prob1 = model1.predict_proba(Xtest1)\n\nX_testtext2 = tfidf2.transform(test['word_representation']).toarray()\nXtest2 = pd.DataFrame(X_testtext2)\ny_pred_prob2 = model2.predict_proba(Xtest2)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_prob2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_thresh(Ytest, prob):\n    thresholds = []\n    for thresh in np.arange(0.1, 0.501, 0.01):\n        thresh = np.round(thresh, 2)\n        y_pred_comb = [[1 if x > thresh else 0 for idx,x in enumerate(i) ] for i in prob]\n        res = get_metrics(Ytest, y_pred_comb)[0]\n        thresholds.append([thresh, res])\n        #print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n    thresholds.sort(key=lambda x: x[1], reverse=True)\n    best_thresh = thresholds[0][0]\n    print(\"Best threshold: \", best_thresh)\n    return best_thresh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/til2020/word_embeddings.pkl', 'rb') as f:\n    embeddings = pickle.load(f)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install keras-self-attention","execution_count":3,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fcf5d68be10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/keras-self-attention/\u001b[0m\n\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fcf5d761d90>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/keras-self-attention/\u001b[0m\nCollecting keras-self-attention\n  Downloading keras-self-attention-0.46.0.tar.gz (10 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras-self-attention) (1.18.1)\nRequirement already satisfied: Keras in /opt/conda/lib/python3.7/site-packages (from keras-self-attention) (2.3.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (2.10.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.1.2)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.4.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (5.3.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.0.8)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.14.0)\nBuilding wheels for collected packages: keras-self-attention\n  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-py3-none-any.whl size=17278 sha256=32155114f0d4dbcaa5afd30d57c26d12f09ec65ffe7b48f3ef699b661587fd24\n  Stored in directory: /root/.cache/pip/wheels/ec/f7/48/30de93f8333298bad9202aab9b04db0cfd58dcd379b5a5ef1c\nSuccessfully built keras-self-attention\nInstalling collected packages: keras-self-attention\nSuccessfully installed keras-self-attention-0.46.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import Bidirectional\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer()\nsentences = train[\"word_representation\"].values\ntokenizer.fit_on_texts(sentences)\nsequences = tokenizer.texts_to_sequences(sentences)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\nprint(\"max sequence length:\", max(len(s) for s in sequences))","execution_count":4,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"Found 4249 unique tokens.\nmax sequence length: 47\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pad_sequences(sequences, maxlen=50)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = np.zeros((len(word_index) + 1, 100))\nfor word, i in word_index.items():\n    embedding_vector = embeddings.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Embedding\n\nembedding_layer = Embedding(len(word_index) + 1,\n                            100,\n                            weights=[embedding_matrix],\n                            input_length=50,\n                            trainable=False)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Input, LSTM, GlobalMaxPool1D, Dropout, GRU\nfrom keras.layers import Bidirectional\nfrom keras.models import Model\nfrom keras_self_attention import SeqSelfAttention\n\nsequence_input = Input(shape=(50,), dtype='int32')\nembedded_sequences = embedding_layer(sequence_input)\nx = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(embedded_sequences)\nx = SeqSelfAttention(attention_activation='sigmoid')(x)\nx = GlobalMaxPool1D()(x) # consider all the h(t)s but only get 1 output\nx = Dropout(0.2)(x)\n# output = Dense(1, activation=\"sigmoid\")(x)\n#x = Bidirectional(LSTM(128, return_sequences=True))(embedded_sequences)\n#x = Bidirectional(LSTM(64, return_sequences=True))(x)\n#x = Attention(50)(x)\n#x = Dense(64, activation=\"relu\")(x)\n#x = Dropout(0.1)(x)\nx = Dense(5, activation=\"sigmoid\")(x)\n\nmodel = Model(sequence_input, x)\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\nmc = ModelCheckpoint('lstm_att.hdf5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training model...')\nr = model.fit(\n  data,\n  Ytrain,\n  batch_size=128,\n  epochs=200,\n  validation_split=0.1,\n  callbacks=[es, mc]\n)","execution_count":36,"outputs":[{"output_type":"stream","text":"Training model...\nTrain on 6642 samples, validate on 738 samples\nEpoch 1/200\n6642/6642 [==============================] - 12s 2ms/step - loss: 0.5664 - accuracy: 0.6955 - val_loss: 0.4631 - val_accuracy: 0.7751\n\nEpoch 00001: val_loss improved from inf to 0.46314, saving model to lstm_att.hdf5\nEpoch 2/200\n6642/6642 [==============================] - 12s 2ms/step - loss: 0.4298 - accuracy: 0.7939 - val_loss: 0.3436 - val_accuracy: 0.8455\n\nEpoch 00002: val_loss improved from 0.46314 to 0.34356, saving model to lstm_att.hdf5\nEpoch 3/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.3349 - accuracy: 0.8521 - val_loss: 0.2508 - val_accuracy: 0.9030\n\nEpoch 00003: val_loss improved from 0.34356 to 0.25081, saving model to lstm_att.hdf5\nEpoch 4/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.2606 - accuracy: 0.8953 - val_loss: 0.1975 - val_accuracy: 0.9331\n\nEpoch 00004: val_loss improved from 0.25081 to 0.19746, saving model to lstm_att.hdf5\nEpoch 5/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.2159 - accuracy: 0.9176 - val_loss: 0.1721 - val_accuracy: 0.9415\n\nEpoch 00005: val_loss improved from 0.19746 to 0.17212, saving model to lstm_att.hdf5\nEpoch 6/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.1841 - accuracy: 0.9338 - val_loss: 0.1587 - val_accuracy: 0.9461\n\nEpoch 00006: val_loss improved from 0.17212 to 0.15869, saving model to lstm_att.hdf5\nEpoch 7/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.1691 - accuracy: 0.9400 - val_loss: 0.1383 - val_accuracy: 0.9550\n\nEpoch 00007: val_loss improved from 0.15869 to 0.13829, saving model to lstm_att.hdf5\nEpoch 8/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.1533 - accuracy: 0.9464 - val_loss: 0.1623 - val_accuracy: 0.9401\n\nEpoch 00008: val_loss did not improve from 0.13829\nEpoch 9/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.1490 - accuracy: 0.9476 - val_loss: 0.1279 - val_accuracy: 0.9588\n\nEpoch 00009: val_loss improved from 0.13829 to 0.12786, saving model to lstm_att.hdf5\nEpoch 10/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.1347 - accuracy: 0.9551 - val_loss: 0.1178 - val_accuracy: 0.9621\n\nEpoch 00010: val_loss improved from 0.12786 to 0.11777, saving model to lstm_att.hdf5\nEpoch 11/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.1249 - accuracy: 0.9589 - val_loss: 0.1142 - val_accuracy: 0.9631\n\nEpoch 00011: val_loss improved from 0.11777 to 0.11423, saving model to lstm_att.hdf5\nEpoch 12/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.1183 - accuracy: 0.9612 - val_loss: 0.1144 - val_accuracy: 0.9623\n\nEpoch 00012: val_loss did not improve from 0.11423\nEpoch 13/200\n6642/6642 [==============================] - 12s 2ms/step - loss: 0.1137 - accuracy: 0.9630 - val_loss: 0.1049 - val_accuracy: 0.9669\n\nEpoch 00013: val_loss improved from 0.11423 to 0.10486, saving model to lstm_att.hdf5\nEpoch 14/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.1108 - accuracy: 0.9640 - val_loss: 0.1140 - val_accuracy: 0.9656\n\nEpoch 00014: val_loss did not improve from 0.10486\nEpoch 15/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.1044 - accuracy: 0.9667 - val_loss: 0.1055 - val_accuracy: 0.9683\n\nEpoch 00015: val_loss did not improve from 0.10486\nEpoch 16/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0981 - accuracy: 0.9687 - val_loss: 0.1043 - val_accuracy: 0.9683\n\nEpoch 00016: val_loss improved from 0.10486 to 0.10427, saving model to lstm_att.hdf5\nEpoch 17/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0978 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9680\n\nEpoch 00017: val_loss improved from 0.10427 to 0.10350, saving model to lstm_att.hdf5\nEpoch 18/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0949 - accuracy: 0.9696 - val_loss: 0.1015 - val_accuracy: 0.9686\n\nEpoch 00018: val_loss improved from 0.10350 to 0.10151, saving model to lstm_att.hdf5\nEpoch 19/200\n6642/6642 [==============================] - 12s 2ms/step - loss: 0.0938 - accuracy: 0.9699 - val_loss: 0.0990 - val_accuracy: 0.9686\n\nEpoch 00019: val_loss improved from 0.10151 to 0.09902, saving model to lstm_att.hdf5\nEpoch 20/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0892 - accuracy: 0.9715 - val_loss: 0.0939 - val_accuracy: 0.9721\n\nEpoch 00020: val_loss improved from 0.09902 to 0.09389, saving model to lstm_att.hdf5\nEpoch 21/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0830 - accuracy: 0.9743 - val_loss: 0.0936 - val_accuracy: 0.9710\n\nEpoch 00021: val_loss improved from 0.09389 to 0.09359, saving model to lstm_att.hdf5\nEpoch 22/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0805 - accuracy: 0.9752 - val_loss: 0.0942 - val_accuracy: 0.9718\n\nEpoch 00022: val_loss did not improve from 0.09359\nEpoch 23/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0803 - accuracy: 0.9747 - val_loss: 0.0962 - val_accuracy: 0.9721\n\nEpoch 00023: val_loss did not improve from 0.09359\nEpoch 24/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0782 - accuracy: 0.9750 - val_loss: 0.0946 - val_accuracy: 0.9713\n\nEpoch 00024: val_loss did not improve from 0.09359\nEpoch 25/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0765 - accuracy: 0.9752 - val_loss: 0.0920 - val_accuracy: 0.9734\n\nEpoch 00025: val_loss improved from 0.09359 to 0.09204, saving model to lstm_att.hdf5\nEpoch 26/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0725 - accuracy: 0.9765 - val_loss: 0.0901 - val_accuracy: 0.9729\n\nEpoch 00026: val_loss improved from 0.09204 to 0.09013, saving model to lstm_att.hdf5\nEpoch 27/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0725 - accuracy: 0.9770 - val_loss: 0.0878 - val_accuracy: 0.9737\n\nEpoch 00027: val_loss improved from 0.09013 to 0.08776, saving model to lstm_att.hdf5\nEpoch 28/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0690 - accuracy: 0.9782 - val_loss: 0.0896 - val_accuracy: 0.9745\n\nEpoch 00028: val_loss did not improve from 0.08776\nEpoch 29/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.0893 - val_accuracy: 0.9753\n\nEpoch 00029: val_loss did not improve from 0.08776\nEpoch 30/200\n6642/6642 [==============================] - 12s 2ms/step - loss: 0.0663 - accuracy: 0.9789 - val_loss: 0.0867 - val_accuracy: 0.9767\n\nEpoch 00030: val_loss improved from 0.08776 to 0.08672, saving model to lstm_att.hdf5\nEpoch 31/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0646 - accuracy: 0.9787 - val_loss: 0.0849 - val_accuracy: 0.9764\n\nEpoch 00031: val_loss improved from 0.08672 to 0.08489, saving model to lstm_att.hdf5\nEpoch 32/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0615 - accuracy: 0.9800 - val_loss: 0.0874 - val_accuracy: 0.9756\n\nEpoch 00032: val_loss did not improve from 0.08489\nEpoch 33/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0601 - accuracy: 0.9804 - val_loss: 0.0889 - val_accuracy: 0.9753\n\nEpoch 00033: val_loss did not improve from 0.08489\nEpoch 34/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 0.0839 - val_accuracy: 0.9767\n\nEpoch 00034: val_loss improved from 0.08489 to 0.08394, saving model to lstm_att.hdf5\nEpoch 35/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.0843 - val_accuracy: 0.9753\n\nEpoch 00035: val_loss did not improve from 0.08394\nEpoch 36/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 0.0866 - val_accuracy: 0.9772\n\nEpoch 00036: val_loss did not improve from 0.08394\nEpoch 37/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0533 - accuracy: 0.9830 - val_loss: 0.0885 - val_accuracy: 0.9759\n\nEpoch 00037: val_loss did not improve from 0.08394\nEpoch 38/200\n","name":"stdout"},{"output_type":"stream","text":"6642/6642 [==============================] - 10s 2ms/step - loss: 0.0526 - accuracy: 0.9828 - val_loss: 0.0846 - val_accuracy: 0.9772\n\nEpoch 00038: val_loss did not improve from 0.08394\nEpoch 39/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.0894 - val_accuracy: 0.9759\n\nEpoch 00039: val_loss did not improve from 0.08394\nEpoch 40/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.0857 - val_accuracy: 0.9764\n\nEpoch 00040: val_loss did not improve from 0.08394\nEpoch 41/200\n6642/6642 [==============================] - 12s 2ms/step - loss: 0.0476 - accuracy: 0.9842 - val_loss: 0.0861 - val_accuracy: 0.9778\n\nEpoch 00041: val_loss did not improve from 0.08394\nEpoch 42/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0486 - accuracy: 0.9845 - val_loss: 0.0861 - val_accuracy: 0.9778\n\nEpoch 00042: val_loss did not improve from 0.08394\nEpoch 43/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0474 - accuracy: 0.9846 - val_loss: 0.0860 - val_accuracy: 0.9775\n\nEpoch 00043: val_loss did not improve from 0.08394\nEpoch 44/200\n6642/6642 [==============================] - 10s 2ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.0845 - val_accuracy: 0.9783\n\nEpoch 00044: val_loss did not improve from 0.08394\nEpoch 00044: early stopping\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Epoch 34/200\n6642/6642 [==============================] - 11s 2ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 0.0839 - val_accuracy: 0.9767\n\nEpoch 00034: val_loss improved from 0.08489 to 0.08394, saving model to lstm_att.hdf5"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\n#from keras.utils import custom_object_scope\n#with custom_object_scope({'Precision': keras.metrics.Precision(), 'binary_recall':keras.metrics.Recall()}):\n#    model = load_model('/kaggle/working/lstm_att.hdf5', custom_objects={'SeqSelfAttention': SeqSelfAttention})\nmodel = load_model('/kaggle/working/lstm_att2.hdf5', custom_objects={'SeqSelfAttention': SeqSelfAttention})","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequence_input = Input(shape=(50,), dtype='int32')\nembedded_sequences = embedding_layer(sequence_input)\nx = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(embedded_sequences)\nx = SeqSelfAttention(attention_activation='sigmoid')(x)\nx = GlobalMaxPool1D()(x) # consider all the h(t)s but only get 1 output\nx = Dropout(0.2)(x)\nx = Dense(5, activation=\"sigmoid\")(x)\n\nmodel = Model(sequence_input, x)\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc2 = ModelCheckpoint('lstm_att2.hdf5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training model...')\nr = model.fit(\n  data,\n  Ytrain,\n  batch_size=32,\n  epochs=200,\n  validation_split=0.1,\n  callbacks=[es, mc2]\n)","execution_count":51,"outputs":[{"output_type":"stream","text":"Training model...\nTrain on 6642 samples, validate on 738 samples\nEpoch 1/200\n6642/6642 [==============================] - 44s 7ms/step - loss: 0.4722 - accuracy: 0.7590 - val_loss: 0.3070 - val_accuracy: 0.8656\n\nEpoch 00001: val_loss improved from inf to 0.30698, saving model to lstm_att2.hdf5\nEpoch 2/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.2719 - accuracy: 0.8873 - val_loss: 0.1900 - val_accuracy: 0.9301\n\nEpoch 00002: val_loss improved from 0.30698 to 0.19001, saving model to lstm_att2.hdf5\nEpoch 3/200\n6642/6642 [==============================] - 42s 6ms/step - loss: 0.1914 - accuracy: 0.9280 - val_loss: 0.1492 - val_accuracy: 0.9485\n\nEpoch 00003: val_loss improved from 0.19001 to 0.14916, saving model to lstm_att2.hdf5\nEpoch 4/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.1610 - accuracy: 0.9431 - val_loss: 0.1345 - val_accuracy: 0.9556\n\nEpoch 00004: val_loss improved from 0.14916 to 0.13447, saving model to lstm_att2.hdf5\nEpoch 5/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.1402 - accuracy: 0.9525 - val_loss: 0.1215 - val_accuracy: 0.9612\n\nEpoch 00005: val_loss improved from 0.13447 to 0.12155, saving model to lstm_att2.hdf5\nEpoch 6/200\n6642/6642 [==============================] - 42s 6ms/step - loss: 0.1233 - accuracy: 0.9593 - val_loss: 0.1123 - val_accuracy: 0.9656\n\nEpoch 00006: val_loss improved from 0.12155 to 0.11229, saving model to lstm_att2.hdf5\nEpoch 7/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.1162 - accuracy: 0.9622 - val_loss: 0.1043 - val_accuracy: 0.9672\n\nEpoch 00007: val_loss improved from 0.11229 to 0.10432, saving model to lstm_att2.hdf5\nEpoch 8/200\n6642/6642 [==============================] - 44s 7ms/step - loss: 0.1049 - accuracy: 0.9663 - val_loss: 0.1013 - val_accuracy: 0.9715\n\nEpoch 00008: val_loss improved from 0.10432 to 0.10127, saving model to lstm_att2.hdf5\nEpoch 9/200\n6642/6642 [==============================] - 44s 7ms/step - loss: 0.1008 - accuracy: 0.9680 - val_loss: 0.0984 - val_accuracy: 0.9699\n\nEpoch 00009: val_loss improved from 0.10127 to 0.09837, saving model to lstm_att2.hdf5\nEpoch 10/200\n6642/6642 [==============================] - 42s 6ms/step - loss: 0.0935 - accuracy: 0.9702 - val_loss: 0.0945 - val_accuracy: 0.9710\n\nEpoch 00010: val_loss improved from 0.09837 to 0.09447, saving model to lstm_att2.hdf5\nEpoch 11/200\n6642/6642 [==============================] - 43s 7ms/step - loss: 0.0891 - accuracy: 0.9714 - val_loss: 0.0906 - val_accuracy: 0.9724\n\nEpoch 00011: val_loss improved from 0.09447 to 0.09064, saving model to lstm_att2.hdf5\nEpoch 12/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0845 - accuracy: 0.9737 - val_loss: 0.0916 - val_accuracy: 0.9713\n\nEpoch 00012: val_loss did not improve from 0.09064\nEpoch 13/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0821 - accuracy: 0.9740 - val_loss: 0.0859 - val_accuracy: 0.9745\n\nEpoch 00013: val_loss improved from 0.09064 to 0.08589, saving model to lstm_att2.hdf5\nEpoch 14/200\n6642/6642 [==============================] - 42s 6ms/step - loss: 0.0760 - accuracy: 0.9768 - val_loss: 0.0844 - val_accuracy: 0.9751\n\nEpoch 00014: val_loss improved from 0.08589 to 0.08437, saving model to lstm_att2.hdf5\nEpoch 15/200\n6642/6642 [==============================] - 43s 7ms/step - loss: 0.0724 - accuracy: 0.9772 - val_loss: 0.0835 - val_accuracy: 0.9745\n\nEpoch 00015: val_loss improved from 0.08437 to 0.08350, saving model to lstm_att2.hdf5\nEpoch 16/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0692 - accuracy: 0.9782 - val_loss: 0.0814 - val_accuracy: 0.9748\n\nEpoch 00016: val_loss improved from 0.08350 to 0.08144, saving model to lstm_att2.hdf5\nEpoch 17/200\n6642/6642 [==============================] - 41s 6ms/step - loss: 0.0676 - accuracy: 0.9788 - val_loss: 0.0839 - val_accuracy: 0.9737\n\nEpoch 00017: val_loss did not improve from 0.08144\nEpoch 18/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 0.0871 - val_accuracy: 0.9734\n\nEpoch 00018: val_loss did not improve from 0.08144\nEpoch 19/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0609 - accuracy: 0.9805 - val_loss: 0.0815 - val_accuracy: 0.9775\n\nEpoch 00019: val_loss did not improve from 0.08144\nEpoch 20/200\n6642/6642 [==============================] - 42s 6ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.0870 - val_accuracy: 0.9762\n\nEpoch 00020: val_loss did not improve from 0.08144\nEpoch 21/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 0.0869 - val_accuracy: 0.9767\n\nEpoch 00021: val_loss did not improve from 0.08144\nEpoch 22/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0527 - accuracy: 0.9836 - val_loss: 0.0834 - val_accuracy: 0.9775\n\nEpoch 00022: val_loss did not improve from 0.08144\nEpoch 23/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0486 - accuracy: 0.9848 - val_loss: 0.0854 - val_accuracy: 0.9775\n\nEpoch 00023: val_loss did not improve from 0.08144\nEpoch 24/200\n6642/6642 [==============================] - 42s 6ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 0.0848 - val_accuracy: 0.9772\n\nEpoch 00024: val_loss did not improve from 0.08144\nEpoch 25/200\n6642/6642 [==============================] - 42s 6ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 0.0818 - val_accuracy: 0.9780\n\nEpoch 00025: val_loss did not improve from 0.08144\nEpoch 26/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.0843 - val_accuracy: 0.9775\n\nEpoch 00026: val_loss did not improve from 0.08144\nEpoch 00026: early stopping\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Epoch 16/200\n6642/6642 [==============================] - 43s 6ms/step - loss: 0.0692 - accuracy: 0.9782 - val_loss: 0.0814 - val_accuracy: 0.9748\n\nEpoch 00016: val_loss improved from 0.08350 to 0.08144, saving model to lstm_att2.hdf5"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentences = test[\"word_representation\"].values\ntest_sequences = tokenizer.texts_to_sequences(test_sentences)\nXtest_emb = pad_sequences(test_sequences, maxlen=50)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predembprob = model.predict(Xtest_emb)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequence_input = Input(shape=(50,), dtype='int32')\nembedded_sequences = embedding_layer(sequence_input)\nx = Bidirectional(GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(embedded_sequences)\nx = SeqSelfAttention(attention_activation='sigmoid')(x)\nx = GlobalMaxPool1D()(x) # consider all the h(t)s but only get 1 output\nx = Dropout(0.2)(x)\nx = Dense(5, activation=\"sigmoid\")(x)\n\nmodel_gru = Model(sequence_input, x)\nmodel_gru.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc3 = ModelCheckpoint('gru_att.hdf5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training model...')\nr = model_gru.fit(\n  data,\n  Ytrain,\n  batch_size=32,\n  epochs=200,\n  validation_split=0.1,\n  callbacks=[es, mc3]\n)","execution_count":66,"outputs":[{"output_type":"stream","text":"Training model...\nTrain on 6642 samples, validate on 738 samples\nEpoch 1/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.5114 - accuracy: 0.7394 - val_loss: 0.4503 - val_accuracy: 0.7965\n\nEpoch 00001: val_loss improved from inf to 0.45033, saving model to gru_att.hdf5\nEpoch 2/200\n6642/6642 [==============================] - 50s 8ms/step - loss: 0.3888 - accuracy: 0.8444 - val_loss: 0.3760 - val_accuracy: 0.8572\n\nEpoch 00002: val_loss improved from 0.45033 to 0.37605, saving model to gru_att.hdf5\nEpoch 3/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.3233 - accuracy: 0.8706 - val_loss: 0.3215 - val_accuracy: 0.8921\n\nEpoch 00003: val_loss improved from 0.37605 to 0.32150, saving model to gru_att.hdf5\nEpoch 4/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.2975 - accuracy: 0.8849 - val_loss: 0.2946 - val_accuracy: 0.9051\n\nEpoch 00004: val_loss improved from 0.32150 to 0.29461, saving model to gru_att.hdf5\nEpoch 5/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.2589 - accuracy: 0.9033 - val_loss: 0.2705 - val_accuracy: 0.9163\n\nEpoch 00005: val_loss improved from 0.29461 to 0.27051, saving model to gru_att.hdf5\nEpoch 6/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.2594 - accuracy: 0.9031 - val_loss: 0.2551 - val_accuracy: 0.9149\n\nEpoch 00006: val_loss improved from 0.27051 to 0.25513, saving model to gru_att.hdf5\nEpoch 7/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.2319 - accuracy: 0.9146 - val_loss: 0.2334 - val_accuracy: 0.9266\n\nEpoch 00007: val_loss improved from 0.25513 to 0.23344, saving model to gru_att.hdf5\nEpoch 8/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.2258 - accuracy: 0.9181 - val_loss: 0.2160 - val_accuracy: 0.9331\n\nEpoch 00008: val_loss improved from 0.23344 to 0.21604, saving model to gru_att.hdf5\nEpoch 9/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.2182 - accuracy: 0.9213 - val_loss: 0.2180 - val_accuracy: 0.9301\n\nEpoch 00009: val_loss did not improve from 0.21604\nEpoch 10/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.2053 - accuracy: 0.9246 - val_loss: 0.2101 - val_accuracy: 0.9325\n\nEpoch 00010: val_loss improved from 0.21604 to 0.21010, saving model to gru_att.hdf5\nEpoch 11/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.1950 - accuracy: 0.9288 - val_loss: 0.1948 - val_accuracy: 0.9442\n\nEpoch 00011: val_loss improved from 0.21010 to 0.19477, saving model to gru_att.hdf5\nEpoch 12/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.1796 - accuracy: 0.9352 - val_loss: 0.1836 - val_accuracy: 0.9431\n\nEpoch 00012: val_loss improved from 0.19477 to 0.18357, saving model to gru_att.hdf5\nEpoch 13/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.1702 - accuracy: 0.9403 - val_loss: 0.1717 - val_accuracy: 0.9488\n\nEpoch 00013: val_loss improved from 0.18357 to 0.17166, saving model to gru_att.hdf5\nEpoch 14/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.1587 - accuracy: 0.9445 - val_loss: 0.1617 - val_accuracy: 0.9499\n\nEpoch 00014: val_loss improved from 0.17166 to 0.16175, saving model to gru_att.hdf5\nEpoch 15/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.1627 - accuracy: 0.9461 - val_loss: 0.1643 - val_accuracy: 0.9469\n\nEpoch 00015: val_loss did not improve from 0.16175\nEpoch 16/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.1540 - accuracy: 0.9463 - val_loss: 0.1581 - val_accuracy: 0.9512\n\nEpoch 00016: val_loss improved from 0.16175 to 0.15814, saving model to gru_att.hdf5\nEpoch 17/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.1458 - accuracy: 0.9502 - val_loss: 0.1513 - val_accuracy: 0.9501\n\nEpoch 00017: val_loss improved from 0.15814 to 0.15128, saving model to gru_att.hdf5\nEpoch 18/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.1428 - accuracy: 0.9508 - val_loss: 0.1504 - val_accuracy: 0.9556\n\nEpoch 00018: val_loss improved from 0.15128 to 0.15036, saving model to gru_att.hdf5\nEpoch 19/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1370 - accuracy: 0.9547 - val_loss: 0.1440 - val_accuracy: 0.9575\n\nEpoch 00019: val_loss improved from 0.15036 to 0.14397, saving model to gru_att.hdf5\nEpoch 20/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1251 - accuracy: 0.9591 - val_loss: 0.1348 - val_accuracy: 0.9585\n\nEpoch 00020: val_loss improved from 0.14397 to 0.13484, saving model to gru_att.hdf5\nEpoch 21/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.2357 - accuracy: 0.9560 - val_loss: 0.1397 - val_accuracy: 0.9569\n\nEpoch 00021: val_loss did not improve from 0.13484\nEpoch 22/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1291 - accuracy: 0.9563 - val_loss: 0.1352 - val_accuracy: 0.9569\n\nEpoch 00022: val_loss did not improve from 0.13484\nEpoch 23/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1213 - accuracy: 0.9597 - val_loss: 0.1305 - val_accuracy: 0.9599\n\nEpoch 00023: val_loss improved from 0.13484 to 0.13046, saving model to gru_att.hdf5\nEpoch 24/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1123 - accuracy: 0.9622 - val_loss: 0.1270 - val_accuracy: 0.9626\n\nEpoch 00024: val_loss improved from 0.13046 to 0.12698, saving model to gru_att.hdf5\nEpoch 25/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.1089 - accuracy: 0.9638 - val_loss: 0.1248 - val_accuracy: 0.9602\n\nEpoch 00025: val_loss improved from 0.12698 to 0.12475, saving model to gru_att.hdf5\nEpoch 26/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1074 - accuracy: 0.9659 - val_loss: 0.1244 - val_accuracy: 0.9580\n\nEpoch 00026: val_loss improved from 0.12475 to 0.12436, saving model to gru_att.hdf5\nEpoch 27/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1010 - accuracy: 0.9659 - val_loss: 0.1191 - val_accuracy: 0.9626\n\nEpoch 00027: val_loss improved from 0.12436 to 0.11909, saving model to gru_att.hdf5\nEpoch 28/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.1063 - accuracy: 0.9678 - val_loss: 0.1141 - val_accuracy: 0.9659\n\nEpoch 00028: val_loss improved from 0.11909 to 0.11412, saving model to gru_att.hdf5\nEpoch 29/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1092 - accuracy: 0.9662 - val_loss: 0.1207 - val_accuracy: 0.9623\n\nEpoch 00029: val_loss did not improve from 0.11412\nEpoch 30/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0946 - accuracy: 0.9687 - val_loss: 0.1129 - val_accuracy: 0.9640\n\nEpoch 00030: val_loss improved from 0.11412 to 0.11294, saving model to gru_att.hdf5\nEpoch 31/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.0903 - accuracy: 0.9702 - val_loss: 0.1121 - val_accuracy: 0.9656\n\nEpoch 00031: val_loss improved from 0.11294 to 0.11210, saving model to gru_att.hdf5\nEpoch 32/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0882 - accuracy: 0.9711 - val_loss: 0.1099 - val_accuracy: 0.9661\n\nEpoch 00032: val_loss improved from 0.11210 to 0.10988, saving model to gru_att.hdf5\nEpoch 33/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0811 - accuracy: 0.9722 - val_loss: 0.1047 - val_accuracy: 0.9664\n\nEpoch 00033: val_loss improved from 0.10988 to 0.10467, saving model to gru_att.hdf5\nEpoch 34/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1093 - accuracy: 0.9731 - val_loss: 0.1080 - val_accuracy: 0.9656\n\nEpoch 00034: val_loss did not improve from 0.10467\nEpoch 35/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0879 - accuracy: 0.9709 - val_loss: 0.1035 - val_accuracy: 0.9678\n\nEpoch 00035: val_loss improved from 0.10467 to 0.10352, saving model to gru_att.hdf5\nEpoch 36/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.1081 - accuracy: 0.9724 - val_loss: 0.1039 - val_accuracy: 0.9675\n\nEpoch 00036: val_loss did not improve from 0.10352\nEpoch 37/200\n","name":"stdout"},{"output_type":"stream","text":"6642/6642 [==============================] - 52s 8ms/step - loss: 0.0825 - accuracy: 0.9721 - val_loss: 0.1013 - val_accuracy: 0.9669\n\nEpoch 00037: val_loss improved from 0.10352 to 0.10128, saving model to gru_att.hdf5\nEpoch 38/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0816 - accuracy: 0.9758 - val_loss: 0.1040 - val_accuracy: 0.9656\n\nEpoch 00038: val_loss did not improve from 0.10128\nEpoch 39/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0777 - accuracy: 0.9747 - val_loss: 0.0977 - val_accuracy: 0.9691\n\nEpoch 00039: val_loss improved from 0.10128 to 0.09767, saving model to gru_att.hdf5\nEpoch 40/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.0776 - accuracy: 0.9764 - val_loss: 0.1023 - val_accuracy: 0.9696\n\nEpoch 00040: val_loss did not improve from 0.09767\nEpoch 41/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0730 - accuracy: 0.9761 - val_loss: 0.0980 - val_accuracy: 0.9696\n\nEpoch 00041: val_loss did not improve from 0.09767\nEpoch 42/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0689 - accuracy: 0.9770 - val_loss: 0.0978 - val_accuracy: 0.9699\n\nEpoch 00042: val_loss did not improve from 0.09767\nEpoch 43/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0659 - accuracy: 0.9787 - val_loss: 0.0970 - val_accuracy: 0.9691\n\nEpoch 00043: val_loss improved from 0.09767 to 0.09702, saving model to gru_att.hdf5\nEpoch 44/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.0986 - val_accuracy: 0.9683\n\nEpoch 00044: val_loss did not improve from 0.09702\nEpoch 45/200\n6642/6642 [==============================] - 51s 8ms/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.0978 - val_accuracy: 0.9699\n\nEpoch 00045: val_loss did not improve from 0.09702\nEpoch 46/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0629 - accuracy: 0.9793 - val_loss: 0.0957 - val_accuracy: 0.9696\n\nEpoch 00046: val_loss improved from 0.09702 to 0.09574, saving model to gru_att.hdf5\nEpoch 47/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0590 - accuracy: 0.9813 - val_loss: 0.0931 - val_accuracy: 0.9707\n\nEpoch 00047: val_loss improved from 0.09574 to 0.09306, saving model to gru_att.hdf5\nEpoch 48/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.0949 - val_accuracy: 0.9705\n\nEpoch 00048: val_loss did not improve from 0.09306\nEpoch 49/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0599 - accuracy: 0.9821 - val_loss: 0.0979 - val_accuracy: 0.9702\n\nEpoch 00049: val_loss did not improve from 0.09306\nEpoch 50/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.0977 - val_accuracy: 0.9691\n\nEpoch 00050: val_loss did not improve from 0.09306\nEpoch 51/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9718\n\nEpoch 00051: val_loss did not improve from 0.09306\nEpoch 52/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0611 - accuracy: 0.9824 - val_loss: 0.0916 - val_accuracy: 0.9718\n\nEpoch 00052: val_loss improved from 0.09306 to 0.09157, saving model to gru_att.hdf5\nEpoch 53/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0974 - accuracy: 0.9815 - val_loss: 0.0926 - val_accuracy: 0.9713\n\nEpoch 00053: val_loss did not improve from 0.09157\nEpoch 54/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0534 - accuracy: 0.9826 - val_loss: 0.0947 - val_accuracy: 0.9705\n\nEpoch 00054: val_loss did not improve from 0.09157\nEpoch 55/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0566 - accuracy: 0.9833 - val_loss: 0.0950 - val_accuracy: 0.9713\n\nEpoch 00055: val_loss did not improve from 0.09157\nEpoch 56/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0669 - accuracy: 0.9778 - val_loss: 0.0945 - val_accuracy: 0.9718\n\nEpoch 00056: val_loss did not improve from 0.09157\nEpoch 57/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0561 - accuracy: 0.9814 - val_loss: 0.0939 - val_accuracy: 0.9702\n\nEpoch 00057: val_loss did not improve from 0.09157\nEpoch 58/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0535 - accuracy: 0.9830 - val_loss: 0.0918 - val_accuracy: 0.9718\n\nEpoch 00058: val_loss did not improve from 0.09157\nEpoch 59/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0503 - accuracy: 0.9839 - val_loss: 0.0904 - val_accuracy: 0.9729\n\nEpoch 00059: val_loss improved from 0.09157 to 0.09039, saving model to gru_att.hdf5\nEpoch 60/200\n6642/6642 [==============================] - 54s 8ms/step - loss: 0.0477 - accuracy: 0.9843 - val_loss: 0.0932 - val_accuracy: 0.9729\n\nEpoch 00060: val_loss did not improve from 0.09039\nEpoch 61/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0485 - accuracy: 0.9837 - val_loss: 0.0893 - val_accuracy: 0.9724\n\nEpoch 00061: val_loss improved from 0.09039 to 0.08929, saving model to gru_att.hdf5\nEpoch 62/200\n6642/6642 [==============================] - 53s 8ms/step - loss: 0.0500 - accuracy: 0.9838 - val_loss: 0.0915 - val_accuracy: 0.9726\n\nEpoch 00062: val_loss did not improve from 0.08929\nEpoch 63/200\n6642/6642 [==============================] - 52s 8ms/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.0921 - val_accuracy: 0.9715\n\nEpoch 00063: val_loss did not improve from 0.08929\nEpoch 64/200\n1280/6642 [====>.........................] - ETA: 42s - loss: 0.0468 - accuracy: 0.9852","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-76adc67b906e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gru = load_model('/kaggle/working/gru_att.hdf5', custom_objects={'SeqSelfAttention': SeqSelfAttention})","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predgruprob = model_gru.predict(Xtest_emb)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_prob1)","execution_count":74,"outputs":[{"output_type":"stream","text":"[[1.7546068e-01 9.9387217e-01 9.7000837e-01 2.0070560e-04 6.3888630e-04]\n [9.9884665e-01 9.9845517e-01 1.4060500e-02 5.5575245e-05 3.0075426e-03]\n [9.9818230e-01 1.4843052e-02 9.9365497e-01 1.7182056e-04 6.9535832e-05]\n ...\n [9.8401606e-01 2.4958175e-02 9.9619764e-01 8.1978057e-04 5.0399199e-02]\n [8.5620308e-01 9.8773277e-01 9.9365342e-01 5.6184428e-05 1.5094389e-04]\n [2.1471357e-02 9.7366516e-03 9.8306781e-01 2.6072455e-03 9.9987042e-01]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_prob2)","execution_count":75,"outputs":[{"output_type":"stream","text":"[[2.10789725e-01 9.82939124e-01 9.73868847e-01 1.07290718e-04\n  5.78892359e-04]\n [9.97117043e-01 9.99498487e-01 6.70479052e-03 7.46134960e-04\n  2.34530703e-03]\n [9.98438776e-01 1.08066425e-02 9.96100783e-01 1.46862396e-04\n  9.58087840e-05]\n ...\n [9.83061135e-01 2.01729294e-02 9.96654510e-01 3.56607197e-04\n  1.65813938e-02]\n [6.96623385e-01 9.95002329e-01 9.92879450e-01 8.17008840e-05\n  2.21126073e-04]\n [2.01649722e-02 4.47501335e-03 9.63162601e-01 1.87176731e-04\n  9.99941707e-01]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_predembprob)","execution_count":76,"outputs":[{"output_type":"stream","text":"[[1.4214219e-02 9.9895084e-01 9.9488539e-01 3.4931168e-04 2.3434998e-04]\n [9.8853439e-01 9.9916184e-01 2.3438616e-03 5.0843752e-04 1.4850023e-03]\n [9.9951744e-01 8.9493617e-03 9.9914849e-01 9.6736057e-04 4.3327658e-04]\n ...\n [9.9842322e-01 1.4080577e-02 9.9722469e-01 5.1101629e-04 2.9133479e-04]\n [6.1549615e-02 9.8918962e-01 9.9936348e-01 3.4531410e-04 8.0461803e-05]\n [2.9324330e-02 4.2786676e-02 9.8343444e-01 9.5768814e-04 9.6736532e-01]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_predgruprob)","execution_count":77,"outputs":[{"output_type":"stream","text":"[[1.3381267e-02 9.9979299e-01 9.2557770e-01 2.2734902e-04 1.8657146e-03]\n [9.8551047e-01 9.9987984e-01 7.7461742e-04 7.5418281e-04 4.9878992e-03]\n [9.9991119e-01 3.4067675e-03 9.9993360e-01 1.2145685e-04 2.1914857e-05]\n ...\n [9.9997032e-01 4.6680467e-03 9.4775236e-01 1.0693732e-04 1.7644659e-04]\n [4.2718604e-01 9.9452317e-01 9.9911159e-01 7.5989979e-04 8.0967555e-05]\n [3.5760734e-02 2.0039266e-03 9.9944478e-01 3.6785175e-04 9.8892468e-01]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_combprob = 0.25*(y_pred_prob1+y_pred_prob2+y_predembprob+y_predgruprob)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_combprob)","execution_count":78,"outputs":[{"output_type":"stream","text":"[[1.03461474e-01 9.93888795e-01 9.66085076e-01 2.21164257e-04\n  8.29460798e-04]\n [9.92502093e-01 9.99248862e-01 5.97094232e-03 5.16082626e-04\n  2.95643788e-03]\n [9.99012470e-01 9.50145628e-03 9.97209430e-01 3.51875089e-04\n  1.55134010e-04]\n ...\n [9.91367698e-01 1.59699321e-02 9.84457374e-01 4.48585342e-04\n  1.68620925e-02]\n [5.10390520e-01 9.91611958e-01 9.96252000e-01 3.10774805e-04\n  1.33374822e-04]\n [2.66803466e-02 1.47505673e-02 9.82277393e-01 1.02999050e-03\n  9.89025533e-01]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#threshcomb = calculate_thresh(Ytest, y_pred_combprob)\ny_predcomb = [[1 if x > 0.35 else 0 for idx,x in enumerate(i) ] for i in y_pred_combprob]","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/til2020/NLP_submission_example.csv')\nsubmission[[\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"]] = y_predcomb\nsubmission.to_csv('submission5.csv', index=False)","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}